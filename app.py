import streamlit as st
import os
import gdown
import zipfile
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# ==========================================
# 1. è¨­å®šå€ï¼šè«‹å¡«å…¥æ‚¨çš„ Google Drive File ID
# ==========================================
# ç¯„ä¾‹ï¼šå¦‚æœé€£çµæ˜¯ https://drive.google.com/file/d/1xxxx/view...
# é€™è£¡å°±å¡«å…¥ "1xxxx"
GDRIVE_FILE_ID = "1iwvWuIZlLRzirPlOZAwJhNlnCza9y5Yt" 

# ==========================================
# 2. å®šç¾© Embedding æ¨¡å‹ (å¿…é ˆèˆ‡å»ºç«‹æ™‚ä¸€è‡´)
# ==========================================
class EmbeddingGemmaEmbeddings(HuggingFaceEmbeddings):
    def __init__(self, **kwargs):
        super().__init__(
            model_name="google/embeddinggemma-300m",
            encode_kwargs={"normalize_embeddings": True},
            **kwargs
        )

    def embed_documents(self, texts):
        # ä¿®æ­£ï¼šæ”¹æˆé€šç”¨çš„æ¨™é¡Œï¼Œé¿å…èª¤å°
        texts = [f"title: ä¿éšªå•†å“æ¢æ¬¾ | text: {t}" for t in texts]
        return super().embed_documents(texts)

    def embed_query(self, text):
        return super().embed_query(f"task: search result | query: {text}")

# ==========================================
# 3. ç³»çµ±åˆå§‹åŒ–èˆ‡è³‡æ–™åº«ä¸‹è¼‰
# ==========================================
st.set_page_config(page_title="å°ˆæ¥­ä¿éšªè«®è©¢ AI", layout="wide")
st.title("ğŸ›¡ï¸ å°ˆæ¥­ä¿éšªè«®è©¢èˆ‡æ¨è–¦ç³»çµ±")

if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    api_key = st.secrets["GROQ_API_KEY"]
else:
    st.error("âŒ æœªè¨­å®š GROQ_API_KEYï¼Œè«‹è‡³ Streamlit Secrets é€²è¡Œè¨­å®šã€‚")
    st.stop()

@st.cache_resource
def load_resources():
    folder_name = "faiss_db_checkpoint"
    zip_name = "faiss_db_checkpoint.zip"
    
    # 1. æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡ä¸‹è¼‰
    if not os.path.exists(folder_name):
        if not os.path.exists(zip_name):
            if "è«‹å°‡æ‚¨çš„" in GDRIVE_FILE_ID:
                st.error("âš ï¸ è«‹å…ˆåœ¨ app.py ç¬¬ 16 è¡Œå¡«å…¥æ­£ç¢ºçš„ Google Drive File IDï¼")
                st.stop()
                
            with st.spinner("ğŸ“¦ æ­£åœ¨å¾é›²ç«¯ä¸‹è¼‰è³‡æ–™åº« (åˆæ¬¡å•Ÿå‹•éœ€æ™‚è¼ƒé•·)..."):
                try:
                    url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}'
                    gdown.download(url, zip_name, quiet=False)
                except Exception as e:
                    st.error(f"ä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¢ºèª File ID æ­£ç¢ºä¸”æ¬Šé™å·²é–‹ã€‚éŒ¯èª¤: {e}")
                    st.stop()
        
        # 2. è§£å£“ç¸®
        with st.spinner("ğŸ“‚ æ­£åœ¨è§£å£“ç¸®è³‡æ–™åº«..."):
            try:
                with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                    zip_ref.extractall(".") # è§£å£“åˆ°ç•¶å‰ç›®éŒ„
            except Exception as e:
                st.error(f"è§£å£“ç¸®å¤±æ•—: {e}")
                st.stop()

    # 3. è¼‰å…¥ FAISS
    try:
        embeddings = EmbeddingGemmaEmbeddings()
        db = FAISS.load_local(
            folder_name, 
            embeddings,
            allow_dangerous_deserialization=True
        )
        return db
    except Exception as e:
        st.error(f"è³‡æ–™åº«è®€å–å¤±æ•—ï¼š{e}")
        return None

vectorstore = load_resources()

if not vectorstore:
    st.stop()

retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# è¨­å®š LLM
llm = ChatOpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=api_key,
    model="llama3-70b-8192", 
    temperature=0.3,         
)

# ==========================================
# 4. Prompt è¨­å®š
# ==========================================
persona_instruction = """
ä½ æ˜¯å°ˆæ¥­ä¸”å……æ»¿ç†±å¿±çš„ä¿éšªæ¥­å‹™å“¡ï¼Œè‡´åŠ›æ–¼æä¾›æœ€å„ªè³ªçš„æœå‹™ã€‚
ä½ æ“æœ‰å¸‚é¢ä¸Šå¹¾å®¶å¤§å‹ä¿éšªå…¬å¸çš„æ‰€æœ‰ä¿éšªå•†å“è³‡æ–™ã€‚

è«‹å‹™å¿…åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
1. **åªèƒ½**æ ¹æ“šä¸‹æ–¹çš„ã€å·²çŸ¥è³‡è¨Šã€‘ä¾†å›ç­”å•é¡Œã€‚
2. è‹¥è³‡æ–™ä¸è¶³æˆ–é¡Œç›®è¶…éèƒ½åŠ›ç¯„åœï¼Œè«‹å›ç­”ï¼šã€Œä¸å¥½æ„æ€ï¼Œç›®å‰çš„å…§éƒ¨è³‡æ–™åº«ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œå»ºè­°æ‚¨ç›´æ¥æ´½è©¢è©²ä¿éšªå…¬å¸çš„å°ˆäººå®¢æœæœå‹™ã€‚ã€
3. **æ‹’çµ•å›ç­”**ä»»ä½•è·Ÿä¿éšªä»¥å¤–ç›¸é—œå…§å®¹ï¼ˆä¾‹å¦‚ï¼šé£Ÿè­œã€ç¨‹å¼ç¢¼ã€æ—…éŠæ™¯é»ç­‰ï¼‰ã€‚
4. èªæ°£ä¿æŒè¦ªåˆ‡å‹å–„ã€å°ˆæ¥­ç°¡æ½”ï¼Œä¸¦ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ã€‚
"""

qa_prompt = PromptTemplate(
    template=persona_instruction + """
    
    ã€å·²çŸ¥è³‡è¨Šã€‘ï¼š
    {context}
    
    ä½¿ç”¨è€…å•é¡Œï¼š{question}
    
    å°ˆæ¥­æ¥­å‹™å“¡å›è¦†ï¼š
    """,
    input_variables=["context", "question"]
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": qa_prompt}
)

# ==========================================
# 5. ä»‹é¢åŠŸèƒ½
# ==========================================
tab1, tab2 = st.tabs(["ğŸ’¬ ç·šä¸Šä¿éšªè«®è©¢", "ğŸ“‹ æ™ºèƒ½ä¿éšªæ¨è–¦"])

with tab1:
    st.subheader("æœ‰ä»€éº¼ä¿éšªå•é¡Œæˆ‘å¯ä»¥å¹«æ‚¨å—ï¼Ÿ")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æŸ¥é–±ä¿éšªæ¢æ¬¾..."):
                try:
                    response = qa_chain.invoke({"query": prompt})
                    st.markdown(response["result"])
                    st.session_state.messages.append({"role": "assistant", "content": response["result"]})
                except Exception as e:
                    st.error(f"éŒ¯èª¤ï¼š{e}")

with tab2:
    st.subheader("ç‚ºæ‚¨é‡èº«æ‰“é€ çš„ä¿éšªè¦åŠƒ")
    with st.container(border=True):
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("æ€§åˆ¥", ["ç”·", "å¥³"])
            age = st.number_input("å¹´é½¡", 25, 100, 30)
            job = st.text_input("è·æ¥­", "å·¥ç¨‹å¸«")
        with col2:
            salary = st.selectbox("å¹´æ”¶", ["50è¬ä»¥ä¸‹", "50-100è¬", "100-200è¬", "200è¬ä»¥ä¸Š"])
            budget = st.text_input("é ç®—", "æœˆç¹³ 3000")
        
        ins_type = st.selectbox("éšªç¨®", ["é†«ç™‚éšª", "æ„å¤–éšª", "å„²è“„éšª", "æ—…éŠéšª", "é•·ç…§éšª", "å£½éšª"])
        
        extra_info = ""
        if ins_type == "æ—…éŠéšª":
            dest = st.text_input("åœ‹å®¶")
            days = st.number_input("å¤©æ•¸", 1, 365, 5)
            extra_info = f"å»{dest}æ—…éŠ{days}å¤©"

        if st.button("é–‹å§‹åˆ†æ"):
            with st.spinner("åˆ†æä¸­..."):
                query = f"ä½¿ç”¨è€…ï¼š{gender}, {age}æ­², è·æ¥­{job}, å¹´æ”¶{salary}, é ç®—{budget}ã€‚æƒ³æ‰¾{ins_type}ã€‚{extra_info}ã€‚è«‹æ¨è–¦å•†å“ã€‚"
                response = qa_chain.invoke({"query": query})
                st.markdown(response["result"])