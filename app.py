import streamlit as st
import os
import gdown
import zipfile
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_groq import ChatGroq 

# ==========================================
# 1. ç³»çµ±è¨­å®š
# ==========================================
st.set_page_config(page_title="å°ˆæ¥­ä¿éšªè«®è©¢ AI", layout="wide")
st.title("ğŸ›¡ï¸ å°ˆæ¥­ä¿éšªè«®è©¢èˆ‡æ¨è–¦ç³»çµ± (V3.0 æ™ºèƒ½ç‰ˆ)")

# æª¢æŸ¥ Groq é‡‘é‘°
if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    api_key = st.secrets["GROQ_API_KEY"]
else:
    st.error("âŒ æœªè¨­å®š GROQ_API_KEYï¼Œè«‹è‡³ Streamlit Secrets è¨­å®šã€‚")
    st.stop()

# ==========================================
# 2. è¨­å®š Google Drive ä¸‹è¼‰
# ==========================================
GDRIVE_FILE_ID = "1SWLCi36AvdoOO8oTAflVD9luHyDKQbRL" 
ZIP_NAME = "faiss_db_mini.zip"
DB_FOLDER = "faiss_db_mini"

# ==========================================
# 3. Embedding æ¨¡å‹
# ==========================================
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )

# ==========================================
# 4. è¼‰å…¥è³‡æº (âš ï¸ ä¿®æ­£é»ï¼šç´”æ·¨ç‰ˆï¼Œä¸å«ä»»ä½• UI æŒ‡ä»¤)
# ==========================================
@st.cache_resource(show_spinner=False) # é—œé–‰å…§å»º spinnerï¼Œå®Œå…¨ç”±æˆ‘å€‘æ§åˆ¶
def load_resources():
    """
    é€™å€‹å‡½å¼åªè² è²¬é‹ç®—èˆ‡è³‡æ–™è®€å–ï¼Œ
    çµ•å°ä¸åŒ…å« st.spinner, st.error ç­‰ UI äº’å‹•ã€‚
    """
    # 1. ä¸‹è¼‰èˆ‡è§£å£“ç¸® (åªåšå‹•ä½œï¼Œä¸é¡¯ç¤º st è¨Šæ¯)
    if not os.path.exists(DB_FOLDER):
        if not os.path.exists(ZIP_NAME):
            try:
                url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}'
                gdown.download(url, ZIP_NAME, quiet=False)
            except:
                return None # å¤±æ•—å°±å›å‚³ Noneï¼Œè®“å¤–é¢è™•ç†
        
        try:
            with zipfile.ZipFile(ZIP_NAME, 'r') as zip_ref:
                zip_ref.extractall(".")
        except:
            return None

    # 2. è¼‰å…¥ FAISS
    try:
        embeddings = get_embeddings()
        if os.path.exists(DB_FOLDER):
            load_path = DB_FOLDER
        else:
            load_path = "."
            
        db = FAISS.load_local(
            load_path, 
            embeddings,
            allow_dangerous_deserialization=True
        )
        return db
    except:
        return None

# --- åœ¨ã€Œå‡½å¼å¤–é¢ã€åšè½‰åœˆåœˆç‰¹æ•ˆ ---
with st.spinner("ğŸ“¦ ç³»çµ±å•Ÿå‹•ä¸­ï¼Œæ­£åœ¨è¼‰å…¥ä¿éšªè³‡æ–™åº«..."):
    vectorstore = load_resources()

# --- æ ¹æ“šçµæœé¡¯ç¤º UI ---
if not vectorstore:
    st.error("âŒ è³‡æ–™åº«è¼‰å…¥å¤±æ•—ï¼è«‹æª¢æŸ¥ Requirements æˆ– Google Drive é€£çµã€‚")
    st.stop()
else:
    # æˆåŠŸè¼‰å…¥å¾Œï¼Œå·å·çµ¦å€‹å°æç¤º (é€™æ˜¯å®‰å…¨çš„ï¼Œå› ç‚ºä¸åœ¨ cache å‡½å¼è£¡)
    st.toast("âœ… è³‡æ–™åº«è¼‰å…¥æˆåŠŸï¼", icon="ğŸ§ ")

# è¨­å®šæª¢ç´¢å™¨ (k=8 æ“´å¤§æœå°‹ç¯„åœ)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# ==========================================
# 5. è¨­å®š LLM
# ==========================================
llm = ChatGroq(
    api_key=api_key,
    model="llama-3.1-8b-instant",
    temperature=0.3,
)

# ==========================================
# 6. Prompt èˆ‡ Chain
# ==========================================
persona_instruction = """
ä½ æ˜¯å°ˆæ¥­ã€éˆæ´»ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„è³‡æ·±ä¿éšªé¡§å•ã€‚
ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šã€å·²çŸ¥è³‡è¨Šã€‘(Context) ä¾†å›ç­”ä½¿ç”¨è€…çš„å•é¡Œæˆ–é€²è¡Œå•†å“æ¨è–¦ã€‚

ğŸ”¥ **é‡è¦æ€è€ƒé‚è¼¯ (Chain of Thought)**ï¼š
1. **é—œéµå­—è½‰æ›**ï¼šè‹¥ä½¿ç”¨è€…æåˆ°ç‰¹å®šåœ‹å®¶(å¦‚æ—¥æœ¬ã€ç¾åœ‹)ï¼Œè«‹è‡ªå‹•å°æ‡‰åˆ°æ¢æ¬¾ä¸­çš„ã€Œæµ·å¤–ã€ã€ã€Œåœ‹å¤–ã€æˆ–ã€Œå…¨çƒã€ç›¸é—œè¦å®šã€‚ä¸è¦å› ç‚ºæ²’çœ‹åˆ°åœ‹å®¶åå­—å°±èªªä¸çŸ¥é“ã€‚
2. **è³‡è¨Šæ•´åˆ**ï¼šè‹¥ä½¿ç”¨è€…è©¢å•æ¨è–¦ï¼Œè«‹ç¶œåˆåˆ†æã€å·²çŸ¥è³‡è¨Šã€‘ä¸­çš„å¤šå€‹å•†å“ï¼Œæ¯”è¼ƒå…¶å„ªç¼ºé»ã€‚
3. **èª å¯¦ä½†ç©æ¥µ**ï¼šå¦‚æœè³‡æ–™åº«çœŸçš„å®Œå…¨æ²’æœ‰ç›¸é—œéšªç¨®ï¼Œæ‰å›ç­”ç„¡æ³•æä¾›ï¼›å¦å‰‡è«‹ç›¡é‡å¾ç¾æœ‰è³‡æ–™ä¸­æŒ–æ˜æœ€æ¥è¿‘çš„ç­”æ¡ˆã€‚

ã€å·²çŸ¥è³‡è¨Šã€‘ï¼š
{context}

ä½¿ç”¨è€…å•é¡Œï¼š{question}

è«‹ä»¥å°ç£ç¹é«”ä¸­æ–‡ï¼Œå°ˆæ¥­ä¸”æ¢ç†åˆ†æ˜åœ°å›ç­”ï¼š
"""

qa_prompt = ChatPromptTemplate.from_messages([
    ("human", persona_instruction)
])

def format_docs(docs):
    return "\n\n".join(f"æ–‡ä»¶ä¾†æº: {doc.metadata.get('source', 'æœªçŸ¥')}\nå…§å®¹: {doc.page_content}" for doc in docs)

qa_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | qa_prompt
    | llm
    | StrOutputParser()
)

# ==========================================
# 7. ä»‹é¢åŠŸèƒ½ (å« Debug è¦–çª—)
# ==========================================
tab1, tab2 = st.tabs(["ğŸ’¬ ç·šä¸Šä¿éšªè«®è©¢", "ğŸ“‹ æ™ºèƒ½ä¿éšªæ¨è–¦"])

with tab1:
    st.subheader("ğŸ’¬ æ·±åº¦ä¿éšªè«®è©¢ (V11.0 è³‡æ·±ç†è³ é¡§å•ç‰ˆ)")
    
    # åˆå§‹åŒ–æ­·å²è¨Šæ¯
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # é¡¯ç¤ºæ­·å²å°è©±
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # è™•ç†ä½¿ç”¨è€…è¼¸å…¥
    if user_input := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ (ä¾‹å¦‚ï¼šæ‰‹è¡“éšªæœ‰åŒ…å«é–€è¨ºæ‰‹è¡“å—ï¼Ÿ)..."):
        
        # 1. é¡¯ç¤ºä½¿ç”¨è€…å•é¡Œ
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ§  é¡§å•æ­£åœ¨èª¿é–±éå¾€å°è©±èˆ‡æ¢æ¬¾ç´°ç¯€..."):
                try:
                    # ==========================================
                    # ğŸ”§ å¼•æ“ 1ï¼šå°è©±æ­·å²é‡çµ„ (è§£æ±ºã€Œé‡‘é­šè…¦ã€å•é¡Œ)
                    # ==========================================
                    # åªæœ‰ç•¶æœ‰æ­·å²å°è©±æ™‚æ‰åŸ·è¡Œé‡å¯«
                    search_query = user_input
                    history_context = ""
                    
                    if len(st.session_state.messages) > 1:
                        # å–å‡ºæœ€è¿‘ 4 å¥å°è©±ç•¶ä½œèƒŒæ™¯
                        recent_history = st.session_state.messages[-5:-1] 
                        history_text = "\n".join([f"{m['role']}: {m['content']}" for m in recent_history])
                        
                        # å»ºç«‹ä¸€å€‹è¼•é‡ç´š LLM ä¾†è² è²¬ã€Œç¿»è­¯ã€å•é¡Œ
                        llm_rewriter = ChatGroq(api_key=api_key, model="llama-3.1-8b-instant", temperature=0.1)
                        
                        rewrite_prompt = f"""
                        ä½ æ˜¯æœå°‹å„ªåŒ–å°ˆå®¶ã€‚è«‹æ ¹æ“šã€å°è©±æ­·å²ã€‘å°‡ä½¿ç”¨è€…çš„ã€æœ€æ–°å•é¡Œã€‘æ”¹å¯«æˆä¸€å€‹å®Œæ•´ã€ç¨ç«‹çš„æœå°‹èªå¥ã€‚
                        
                        ã€å°è©±æ­·å²ã€‘ï¼š
                        {history_text}
                        
                        ã€æœ€æ–°å•é¡Œã€‘ï¼š
                        {user_input}
                        
                        ã€ä»»å‹™ã€‘ï¼š
                        å¦‚æœæœ€æ–°å•é¡Œä¾è³´æ–¼æ­·å²(ä¾‹å¦‚åªèªªã€Œé‚£ä½µç™¼ç—‡å‘¢?ã€)ï¼Œè«‹è£œå…¨ä¸»è©(ä¾‹å¦‚ã€Œç™Œç—‡éšªçš„ä½µç™¼ç—‡æ˜¯å¦ç†è³ ?ã€)ã€‚
                        å¦‚æœæœ€æ–°å•é¡Œå·²ç¶“å¾ˆå®Œæ•´ï¼Œè«‹ç›´æ¥è¼¸å‡ºåŸå¥ã€‚
                        **åªè¼¸å‡ºæ”¹å¯«å¾Œçš„å¥å­ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹ã€‚**
                        """
                        # åŸ·è¡Œé‡å¯«
                        search_query = llm_rewriter.invoke(rewrite_prompt).content
                        # (é¸æ“‡æ€§) å¯ä»¥åœ¨é€™è£¡ print å‡ºä¾† debug
                        # print(f"åŸå§‹å•é¡Œ: {user_input} -> å„ªåŒ–æœå°‹: {search_query}")

                    # ==========================================
                    # ğŸ”§ å¼•æ“ 2ï¼šæ ¸ä¿ç´šå¼·åŠ›æœå°‹ (åŒæ­¥ Tab 2 è¦æ ¼)
                    # ==========================================
                    retriever_expert = vectorstore.as_retriever(
                        search_type="mmr", 
                        search_kwargs={"k": 6, "fetch_k": 1000, "lambda_mult": 0.5}
                    )
                    
                    # ä½¿ç”¨ã€Œå„ªåŒ–å¾Œçš„å¥å­ã€å»æœå°‹ï¼Œç²¾æº–åº¦æœƒå¤§å¢
                    retrieved_docs = retriever_expert.invoke(search_query)

                    # Debug è¦–çª—ï¼šè®“æ‚¨çœ‹åˆ° AI åˆ°åº•æŸ¥äº†ä»€éº¼
                    with st.expander(f"ğŸ•µï¸ [ç†è³ è¦–è§’] æœå°‹èªå¥ï¼šã€Œ{search_query}ã€"):
                        if not retrieved_docs:
                            st.warning("âš ï¸ æŸ¥ç„¡ç›¸é—œæ¢æ¬¾ï¼Œè«‹å˜—è©¦æ›´å…·é«”çš„é—œéµå­—ã€‚")
                        for i, doc in enumerate(retrieved_docs):
                            source = doc.metadata.get('source', 'æœªçŸ¥')
                            company = doc.metadata.get('company', 'æœªçŸ¥å…¬å¸')
                            st.markdown(f"**{i+1}. [{company}] {source}**")
                            st.caption(doc.page_content[:150] + "...")

                    # ==========================================
                    # ğŸ”§ å¼•æ“ 3ï¼šç†è³ é¡§å• Prompt (Chain of Thought)
                    # ==========================================
                    # ä½¿ç”¨ä½æº«æ¨¡å‹ï¼Œç¢ºä¿å›ç­”åš´è¬¹
                    llm_advisor = ChatGroq(api_key=api_key, model="llama-3.1-8b-instant", temperature=0.1)

                    persona_prompt = """
                    ä½ æ˜¯å…·å‚™ 20 å¹´ç¶“é©—çš„ã€Œè³‡æ·±ä¿éšªç†è³ é¡§å•ã€ã€‚
                    ä½ çš„å·¥ä½œä¸æ˜¯åªæœ‰è®€æ¢æ¬¾ï¼Œè€Œæ˜¯è¦å¹«å®¢æˆ¶ã€Œè§£é‡‹æ¢æ¬¾èƒŒå¾Œçš„é‚è¼¯ã€èˆ‡ã€Œå¯¦å‹™ç†è³ çœ‰è§’ã€ã€‚

                    ã€å·²çŸ¥æ¢æ¬¾è³‡è¨Šã€‘ï¼š
                    {context}

                    ã€ä½¿ç”¨è€…å•é¡Œã€‘ï¼š
                    {question}

                    ã€å›ç­”ç­–ç•¥ (è«‹åš´æ ¼éµå®ˆ)ã€‘ï¼š
                    1. **ç›´çƒå°æ±º**ï¼šç¬¬ä¸€å¥è©±ç›´æ¥å›ç­” Yes/No æˆ–é‡é»çµè«–ã€‚
                    2. **æ¢æ¬¾ä¾æ“š**ï¼šå¼•ç”¨æ¢æ¬¾ä¸­çš„é—œéµå­— (ä¾‹å¦‚ï¼šã€Œæ ¹æ“šç¬¬ X æ¢...ã€)ã€‚
                    3. **åè©è§£é‡‹**ï¼šå¦‚æœæ¢æ¬¾æœ‰å°ˆæœ‰åè© (å¦‚ã€Œæ—¢å¾€ç—‡ã€ã€ã€Œç­‰å¾…æœŸã€)ï¼Œè«‹ç”¨ç™½è©±æ–‡è§£é‡‹çµ¦å®¢æˆ¶è½ã€‚
                    4. **ğŸš¨ å°ˆå®¶è­¦ç¤º (é™¤å¤–è²¬ä»»)**ï¼šé€™æ˜¯æœ€é‡è¦çš„ï¼è«‹ä¸»å‹•å‘ŠçŸ¥**ã€Œä»€éº¼æƒ…æ³ä¸‹ä¸è³ ã€**ã€‚å°ˆå®¶å°±æ˜¯è¦èƒ½çœ‹åˆ°é™·é˜±ã€‚
                    5. **èˆ‰ä¾‹èªªæ˜**ï¼šè«‹è¨­è¨ˆä¸€å€‹ç°¡çŸ­çš„æƒ…å¢ƒ (ä¾‹å¦‚ï¼šå°æ˜ç™¼ç”Ÿäº†...) ä¾†è¼”åŠ©èªªæ˜ã€‚
                    6. **è³‡æ–™ä¾†æº**ï¼šè«‹åœ¨æœ€å¾Œè¨»æ˜åƒè€ƒäº†å“ªä¸€ä»½æ–‡ä»¶ã€‚

                    è«‹ç”¨å°ç£ç¹é«”ä¸­æ–‡ï¼Œä»¥å°ˆæ¥­ã€è©³ç›¡ä¸”æœ‰æº«åº¦çš„å£å»å›ç­”ï¼š
                    """

                    qa_chain_expert = ChatPromptTemplate.from_template(persona_prompt) | llm_advisor | StrOutputParser()

                    # æº–å‚™ Context
                    docs_text = "\n\n".join(f"ä¾†æº: {d.metadata.get('source', 'æœªçŸ¥')}\nå…§å®¹: {d.page_content}" for d in retrieved_docs)
                    
                    # ç”Ÿæˆå›ç­”
                    response = qa_chain_expert.invoke({"context": docs_text, "question": user_input})
                    
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})

                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

with tab2:
    st.subheader("ğŸ“‹ å…¨æ–¹ä½æ™ºèƒ½ä¿éšªè¦åŠƒæ›¸ (V10.0 æ ¸ä¿é¢¨éšªè©•ä¼°ç‰ˆ)")
    
    # --- 1. KYC (Know Your Customer) ---
    with st.container(border=True):
        st.markdown("#### ğŸ‘¤ ç¬¬ä¸€æ­¥ï¼šå»ºç«‹æ‚¨çš„é¢¨éšªèˆ‡å¥åº·æª”æ¡ˆ")
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("æ€§åˆ¥", ["ç”·", "å¥³"])
            age = st.number_input("å¯¦æ­²å¹´é½¡", 0, 100, 30)
            job = st.text_input("è·æ¥­", "è»Ÿé«”å·¥ç¨‹å¸«", help="è«‹ç›¡é‡è©³ç´°ï¼Œå½±éŸ¿æ„å¤–éšªè²»ç‡èˆ‡è·æ¥­ç­‰ç´š")
            
            # ğŸ”¥ æ–°å¢ï¼šç”Ÿæ´»ç¿’æ…£ (å½±éŸ¿å£½éšª/é†«ç™‚éšªè²»ç‡)
            lifestyle = st.multiselect("ç”Ÿæ´»ç¿’æ…£ (å½±éŸ¿è²»ç‡)", ["å¸è¸", "é£²é…’", "åš¼æª³æ¦”", "è¦å¾‹é‹å‹•", "ç„¡ä¸è‰¯å—œå¥½"], default=["ç„¡ä¸è‰¯å—œå¥½"])
            
        with col2:
            salary = st.selectbox("å¹´æ”¶å…¥", ["50è¬ä»¥ä¸‹", "50-100è¬", "100-200è¬", "200è¬ä»¥ä¸Š"])
            family_status = st.selectbox("å®¶åº­è²¬ä»»", ["å–®èº«æœªå©š", "å·²å©šç„¡å­", "å·²å©šæœ‰å­ (å°å­©å¹¼é½¡)", "å·²å©šæœ‰å­ (å°å­©å·²ç¨ç«‹)", "å–®è¦ªå®¶åº­"])
            
            # ğŸ”¥ æ–°å¢ï¼šå¥åº·å‘ŠçŸ¥ (é€™æ˜¯ç¶“ç†äººæœ€åœ¨æ„çš„æ ¸ä¿é—œéµï¼)
            health_history = st.multiselect("éå¾€ç—…å²/å¥åº·ç‹€æ³ (æ ¸ä¿é—œéµ)", 
                ["ç„¡", "é«˜è¡€å£“", "ç³–å°¿ç—…", "å¿ƒè‡Ÿç–¾ç—…", "å…©å¹´å…§æ›¾ä½é™¢/æ‰‹è¡“", "äº”å¹´å…§æ›¾ç½¹æ‚£ç™Œç—‡", "é ˜æœ‰é‡å¤§å‚·ç—…å¡"],
                default=["ç„¡"],
                help="è«‹èª å¯¦å‘ŠçŸ¥ï¼Œé€™å°‡å½±éŸ¿ AI å°æ–¼ã€Œé™¤å¤–è²¬ä»»ã€æˆ–ã€ŒåŠ è²»ã€çš„åˆ¤æ–·"
            )

        st.markdown("#### ğŸ›¡ï¸ ç¬¬äºŒæ­¥ï¼šæ‚¨çš„ä¿éšªéœ€æ±‚èˆ‡é ç®—")
        col3, col4 = st.columns(2)
        with col3:
            ins_type = st.selectbox("æƒ³è¦åŠƒçš„éšªç¨®", 
                ["å£½éšª (å®šæœŸ/çµ‚èº«)", "é†«ç™‚éšª (å¯¦æ”¯å¯¦ä»˜/æ—¥é¡)", "æ„å¤–éšª (å‚·å®³ä¿éšª)", "é‡å¤§å‚·ç—…/ç™Œç—‡éšª", "å„²è“„/ç†è²¡éšª", "æ—…éŠå¹³å®‰éšª"]
            )
        with col4:
            st.markdown("ğŸ’° **é ç®—è¨­å®š**")
            b_col1, b_col2 = st.columns([1, 1])
            with b_col1:
                budget_amount = st.number_input("é‡‘é¡", min_value=0, value=None, step=500, placeholder="è«‹è¼¸å…¥é‡‘é¡")
            with b_col2:
                budget_period = st.selectbox("ç¹³è²»é »ç‡", ["æœˆç¹³", "å¹´ç¹³", "èº‰ç¹³(ä¸€æ¬¡ä»˜æ¸…)"])

        # ç‰¹æ®Šæ¬„ä½
        extra_info = ""
        if "æ—…éŠ" in ins_type:
            dest = st.text_input("æ—…éŠåœ‹å®¶", "æ—¥æœ¬")
            days = st.number_input("å¤©æ•¸", 1, 365, 5)
            extra_info = f"é è¨ˆå‰å¾€{dest}æ—…éŠ{days}å¤©"
        
        has_insurance = st.checkbox("æˆ‘å·²æœ‰é¡ä¼¼ä¿éšª")
        extra_info += "ã€‚å·²æœ‰é¡ä¼¼ä¿å–®ï¼Œé‡é»åœ¨è£œå¼·ã€‚" if has_insurance else "ã€‚æ–°æŠ•ä¿ã€‚"

    # --- 2. é–‹å§‹åˆ†æ ---
    if st.button("ğŸš€ å•Ÿå‹•æ ¸ä¿ç´šåˆ†æ", type="primary"):
        
        # é˜²å‘†
        if budget_amount is None or budget_amount == 0:
            st.warning("âš ï¸ è«‹è¼¸å…¥é ç®—é‡‘é¡ã€‚")
            st.stop()
        
        total_annual_budget = budget_amount * 12 if budget_period == "æœˆç¹³" else budget_amount
        budget_desc = f"{budget_period} {budget_amount} å…ƒ (å¹´ç¹³ç´„ {total_annual_budget} å…ƒ)"

        if "æ—…éŠ" not in ins_type and total_annual_budget < 2000:
            st.error("âŒ é ç®—éä½ï¼Œç„¡æ³•è¦åŠƒæœ‰æ•ˆçš„ä¸»ç´„å•†å“ã€‚")
            st.stop()

        with st.spinner("ğŸ¤– AI æ­£åœ¨é€²è¡Œæ ¸ä¿é¢¨éšªè©•ä¼°èˆ‡æ¢æ¬¾æ¯”å° (fetch_k=1000)..."):
            
            # ç¶­æŒ V9 çš„å¼·åŠ›æœå°‹
            retriever_manager = vectorstore.as_retriever(
                search_type="mmr", 
                search_kwargs={"k": 6, "fetch_k": 1000, "lambda_mult": 0.5}
            )

            search_keyword = f"{ins_type} æ¢æ¬¾ ä¿å–®"
            if "æ—…éŠ" in ins_type:
                search_keyword += f" {dest}"

            retrieved_docs = retriever_manager.invoke(search_keyword)

            with st.expander("ğŸ•µï¸ [å·¥ç¨‹å¸«æ¨¡å¼] æª¢ç´¢åˆ°çš„å€™é¸åå–®"):
                if not retrieved_docs:
                    st.warning("âš ï¸ ç„¡æ³•æª¢ç´¢åˆ°ç›¸é—œæ¢æ¬¾ã€‚")
                for i, doc in enumerate(retrieved_docs):
                    source = doc.metadata.get('source', doc.metadata.get('filename', 'æœªçŸ¥'))
                    company = doc.metadata.get('company', 'æœªçŸ¥å…¬å¸')
                    st.markdown(f"**{i+1}. [{company}] {source}**")
                    st.caption(doc.page_content[:100] + "...")

            # ä½æº«æ¨¡å‹
            llm_strict = ChatGroq(
                api_key=api_key,
                model="llama-3.1-8b-instant",
                temperature=0.2 
            )

            # ==========================================
            # ğŸ”¥ V10 æ ¸å¿ƒï¼šæ ¸ä¿é‚è¼¯ Prompt
            # ==========================================
            query = f"""
            ã€å®¢æˆ¶ç•«åƒ (KYC)ã€‘ï¼š
            - åŸºæœ¬è³‡æ–™ï¼š{gender}, {age}æ­², è·æ¥­ï¼š{job}
            - é ç®—ï¼š{budget_desc} (åš´æ ¼éµå®ˆ)
            - å®¶åº­è²¬ä»»ï¼š{family_status}
            - **å¥åº·ç‹€æ³ (æ ¸ä¿é—œéµ)**ï¼š{', '.join(health_history)} (ğŸ”¥è‹¥æœ‰ç—…å²ï¼Œè«‹æ³¨æ„é™¤å¤–è²¬ä»»æˆ–æ‹’ä¿é¢¨éšª)
            - **ç”Ÿæ´»ç¿’æ…£**ï¼š{', '.join(lifestyle)} (ğŸ”¥è‹¥æœ‰å¸è¸ï¼Œå£½éšªè²»ç‡å¯èƒ½å¢åŠ )
            - éœ€æ±‚ç›®æ¨™ï¼š{ins_type}
            - å‚™è¨»ï¼š{extra_info}

            ã€ä»»å‹™æŒ‡ä»¤ã€‘ï¼š
            ä½ æ˜¯è³‡æ·±çš„ã€Œæ ¸ä¿äººå“¡ã€å…¼ã€Œä¿éšªç¶“ç´€äººã€ã€‚è«‹é–±è®€æª¢ç´¢è³‡æ–™ï¼Œç”¢å‡ºå°ˆæ¥­å»ºè­°æ›¸ã€‚

            1. **æ ¸ä¿é¢¨éšªé åˆ¤**ï¼š
               - è‹¥å®¢æˆ¶æœ‰ã€Œç³–å°¿ç—…/é«˜è¡€å£“ã€ç­‰ç—…å²ï¼Œè«‹åœ¨æ¨è–¦æ™‚æ˜ç¢ºè­¦å‘Šï¼šã€Œæ­¤é«”æ³å¯èƒ½é¢è‡¨åŠ è²»ã€é™¤å¤–æˆ–æ‹’ä¿ã€ã€‚
               - è‹¥å®¢æˆ¶æ˜¯ã€Œé«˜é¢¨éšªè·æ¥­ã€ï¼Œè«‹æª¢æŸ¥æ„å¤–éšªæ¢æ¬¾æ˜¯å¦æ‰¿ä¿ã€‚
            
            2. **æ·±åº¦æ¨è–¦ç†ç”± (Deep Reasoning)**ï¼š
               - ç¦æ­¢åªå¯«ã€Œé€™å¼µå¾ˆå¥½ã€ã€‚
               - å¿…é ˆå¯«å‡ºé‚è¼¯ï¼š**ã€Œå› ç‚ºæ‚¨æ˜¯ [Aèº«ä»½/æœ‰Bé«”æ³]ï¼Œé€™å¼µä¿å–®çš„ [Cæ¢æ¬¾] å°æ‚¨æœ‰åˆ©ï¼Œä¸”ç¬¦åˆæ‚¨çš„ [Dé ç®—]ã€‚ã€**
            
            3. **ç²¾é¸é›™å•†å“æ¯”è¼ƒ**ï¼šæŒ‘é¸ 2 å€‹æ–¹æ¡ˆ (å˜—è©¦ä¸åŒå…¬å¸)ã€‚

            ã€å»ºè­°æ›¸è¼¸å‡ºæ ¼å¼ã€‘ï¼š
            ### ğŸ©º ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸ä¿é¢¨éšªè©•ä¼°
            (é‡å°å®¢æˆ¶çš„å¥åº·ã€è·æ¥­èˆ‡ç”Ÿæ´»ç¿’æ…£ï¼Œé åˆ¤æŠ•ä¿å¯èƒ½é‡åˆ°çš„é˜»ç¤™æˆ–åŠ è²»ç‹€æ³)

            ### ğŸ† ç¬¬äºŒéƒ¨åˆ†ï¼šç²¾é¸æ–¹æ¡ˆæ¨è–¦
            #### æ–¹æ¡ˆ Aï¼š[ä¿éšªå…¬å¸] - [å•†å“åç¨±]
            * **æ ¸å¿ƒå„ªå‹¢**ï¼š(ä¸€å¥è©±äº®é»)
            * **æ·±åº¦æ¨è–¦åŸå› **ï¼š(ğŸ”¥è«‹ä¾ç…§ã€Œä½¿ç”¨è€…ç‰¹å¾µ + æ¢æ¬¾ç´°ç¯€ + è§£æ±ºç—›é»ã€çš„é‚è¼¯æ’°å¯«)
            * **æ ¸ä¿æ³¨æ„äº‹é …**ï¼š(é‡å°è©²å•†å“çš„è·æ¥­æˆ–é«”æ³é™åˆ¶)
            * **è³‡æ–™ä¾†æº**ï¼š(è«‹è¨»æ˜åƒè€ƒæ–‡ä»¶)

            #### æ–¹æ¡ˆ Bï¼š[ä¿éšªå…¬å¸] - [å•†å“åç¨±]
            * **æ ¸å¿ƒå„ªå‹¢**ï¼š...
            * **æ·±åº¦æ¨è–¦åŸå› **ï¼š...
            * **æ ¸ä¿æ³¨æ„äº‹é …**ï¼š...
            * **è³‡æ–™ä¾†æº**ï¼š...

            ### âš–ï¸ ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¶…ç´šæ¯”ä¸€æ¯”
            | æ¯”è¼ƒé …ç›® | æ–¹æ¡ˆ A | æ–¹æ¡ˆ B |
            | :--- | :--- | :--- |
            | ä¿éšªå…¬å¸ | ... | ... |
            | å•†å“ç‰¹è‰² | ... | ... |
            | æ‰¿ä¿ç¯„åœ | ... | ... |
            | **é ä¼°ä¿è²»** | (ä¾ {budget_period} ä¼°ç®—) | (ä¾ {budget_period} ä¼°ç®—) |

            ### ğŸ’¡ ç¶“ç†äººç¸½çµ
            (çµ¦å®¢æˆ¶çš„æœ€çµ‚å»ºè­°)
            """
            
            try:
                docs_text = "\n\n".join(f"ä¾†æº: {d.metadata.get('source', 'æœªçŸ¥')}\nå…§å®¹: {d.page_content}" for d in retrieved_docs)
                
                prompt_template = ChatPromptTemplate.from_template(query + "\n\nã€æª¢ç´¢åˆ°çš„æ¢æ¬¾å…§å®¹ã€‘ï¼š\n{context}")
                chain = prompt_template | llm_strict | StrOutputParser()
                
                response = chain.invoke({"context": docs_text})
                st.markdown(response)

                st.info("ğŸ’¡ **ç¶“ç†äººå°å®åš€**ï¼š\næœ¬å»ºè­°æ›¸ç”± AI ç³»çµ±ç”Ÿæˆã€‚è‹¥æ‚¨æœ‰ã€Œéå¾€ç—…å²ã€ï¼Œå¯¦éš›æ ¸ä¿çµæœï¼ˆåŠ è²»/é™¤å¤–/æ‹’ä¿ï¼‰å°‡ç”±ä¿éšªå…¬å¸æ ¸ä¿ç§‘æœ€çµ‚æ±ºå®šã€‚")
                
            except Exception as e:
                st.error(f"åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")