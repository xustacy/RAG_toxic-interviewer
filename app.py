import streamlit as st
import os
import gdown
import zipfile
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_groq import ChatGroq 

# ==========================================
# 1. ç³»çµ±è¨­å®š
# ==========================================
st.set_page_config(page_title="å°ˆæ¥­ä¿éšªè«®è©¢ AI", layout="wide")
st.title("ğŸ›¡ï¸ å°ˆæ¥­ä¿éšªè«®è©¢èˆ‡æ¨è–¦ç³»çµ± (V3.0 æ™ºèƒ½ç‰ˆ)")

# æª¢æŸ¥ Groq é‡‘é‘°
if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    api_key = st.secrets["GROQ_API_KEY"]
else:
    st.error("âŒ æœªè¨­å®š GROQ_API_KEYï¼Œè«‹è‡³ Streamlit Secrets è¨­å®šã€‚")
    st.stop()

# ==========================================
# 2. è¨­å®š Google Drive ä¸‹è¼‰
# ==========================================
GDRIVE_FILE_ID = "1SWLCi36AvdoOO8oTAflVD9luHyDKQbRL" 
ZIP_NAME = "faiss_db_mini.zip"
DB_FOLDER = "faiss_db_mini"

# ==========================================
# 3. Embedding æ¨¡å‹
# ==========================================
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )

# ==========================================
# 4. è¼‰å…¥è³‡æº (âš ï¸ ä¿®æ­£é»ï¼šç´”æ·¨ç‰ˆï¼Œä¸å«ä»»ä½• UI æŒ‡ä»¤)
# ==========================================
@st.cache_resource(show_spinner=False) # é—œé–‰å…§å»º spinnerï¼Œå®Œå…¨ç”±æˆ‘å€‘æ§åˆ¶
def load_resources():
    """
    é€™å€‹å‡½å¼åªè² è²¬é‹ç®—èˆ‡è³‡æ–™è®€å–ï¼Œ
    çµ•å°ä¸åŒ…å« st.spinner, st.error ç­‰ UI äº’å‹•ã€‚
    """
    # 1. ä¸‹è¼‰èˆ‡è§£å£“ç¸® (åªåšå‹•ä½œï¼Œä¸é¡¯ç¤º st è¨Šæ¯)
    if not os.path.exists(DB_FOLDER):
        if not os.path.exists(ZIP_NAME):
            try:
                url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}'
                gdown.download(url, ZIP_NAME, quiet=False)
            except:
                return None # å¤±æ•—å°±å›å‚³ Noneï¼Œè®“å¤–é¢è™•ç†
        
        try:
            with zipfile.ZipFile(ZIP_NAME, 'r') as zip_ref:
                zip_ref.extractall(".")
        except:
            return None

    # 2. è¼‰å…¥ FAISS
    try:
        embeddings = get_embeddings()
        if os.path.exists(DB_FOLDER):
            load_path = DB_FOLDER
        else:
            load_path = "."
            
        db = FAISS.load_local(
            load_path, 
            embeddings,
            allow_dangerous_deserialization=True
        )
        return db
    except:
        return None

# --- åœ¨ã€Œå‡½å¼å¤–é¢ã€åšè½‰åœˆåœˆç‰¹æ•ˆ ---
with st.spinner("ğŸ“¦ ç³»çµ±å•Ÿå‹•ä¸­ï¼Œæ­£åœ¨è¼‰å…¥ä¿éšªè³‡æ–™åº«..."):
    vectorstore = load_resources()

# --- æ ¹æ“šçµæœé¡¯ç¤º UI ---
if not vectorstore:
    st.error("âŒ è³‡æ–™åº«è¼‰å…¥å¤±æ•—ï¼è«‹æª¢æŸ¥ Requirements æˆ– Google Drive é€£çµã€‚")
    st.stop()
else:
    # æˆåŠŸè¼‰å…¥å¾Œï¼Œå·å·çµ¦å€‹å°æç¤º (é€™æ˜¯å®‰å…¨çš„ï¼Œå› ç‚ºä¸åœ¨ cache å‡½å¼è£¡)
    st.toast("âœ… è³‡æ–™åº«è¼‰å…¥æˆåŠŸï¼", icon="ğŸ§ ")

# è¨­å®šæª¢ç´¢å™¨ (k=8 æ“´å¤§æœå°‹ç¯„åœ)
retriever = vectorstore.as_retriever(search_kwargs={"k": 8})

# ==========================================
# 5. è¨­å®š LLM
# ==========================================
llm = ChatGroq(
    api_key=api_key,
    model="llama-3.3-70b-versatile", 
    temperature=0.3,
)

# ==========================================
# 6. Prompt èˆ‡ Chain
# ==========================================
persona_instruction = """
ä½ æ˜¯å°ˆæ¥­ã€éˆæ´»ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„è³‡æ·±ä¿éšªé¡§å•ã€‚
ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šã€å·²çŸ¥è³‡è¨Šã€‘(Context) ä¾†å›ç­”ä½¿ç”¨è€…çš„å•é¡Œæˆ–é€²è¡Œå•†å“æ¨è–¦ã€‚

ğŸ”¥ **é‡è¦æ€è€ƒé‚è¼¯ (Chain of Thought)**ï¼š
1. **é—œéµå­—è½‰æ›**ï¼šè‹¥ä½¿ç”¨è€…æåˆ°ç‰¹å®šåœ‹å®¶(å¦‚æ—¥æœ¬ã€ç¾åœ‹)ï¼Œè«‹è‡ªå‹•å°æ‡‰åˆ°æ¢æ¬¾ä¸­çš„ã€Œæµ·å¤–ã€ã€ã€Œåœ‹å¤–ã€æˆ–ã€Œå…¨çƒã€ç›¸é—œè¦å®šã€‚ä¸è¦å› ç‚ºæ²’çœ‹åˆ°åœ‹å®¶åå­—å°±èªªä¸çŸ¥é“ã€‚
2. **è³‡è¨Šæ•´åˆ**ï¼šè‹¥ä½¿ç”¨è€…è©¢å•æ¨è–¦ï¼Œè«‹ç¶œåˆåˆ†æã€å·²çŸ¥è³‡è¨Šã€‘ä¸­çš„å¤šå€‹å•†å“ï¼Œæ¯”è¼ƒå…¶å„ªç¼ºé»ã€‚
3. **èª å¯¦ä½†ç©æ¥µ**ï¼šå¦‚æœè³‡æ–™åº«çœŸçš„å®Œå…¨æ²’æœ‰ç›¸é—œéšªç¨®ï¼Œæ‰å›ç­”ç„¡æ³•æä¾›ï¼›å¦å‰‡è«‹ç›¡é‡å¾ç¾æœ‰è³‡æ–™ä¸­æŒ–æ˜æœ€æ¥è¿‘çš„ç­”æ¡ˆã€‚

ã€å·²çŸ¥è³‡è¨Šã€‘ï¼š
{context}

ä½¿ç”¨è€…å•é¡Œï¼š{question}

è«‹ä»¥å°ç£ç¹é«”ä¸­æ–‡ï¼Œå°ˆæ¥­ä¸”æ¢ç†åˆ†æ˜åœ°å›ç­”ï¼š
"""

qa_prompt = ChatPromptTemplate.from_messages([
    ("human", persona_instruction)
])

def format_docs(docs):
    return "\n\n".join(f"æ–‡ä»¶ä¾†æº: {doc.metadata.get('source', 'æœªçŸ¥')}\nå…§å®¹: {doc.page_content}" for doc in docs)

qa_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | qa_prompt
    | llm
    | StrOutputParser()
)

# ==========================================
# 7. ä»‹é¢åŠŸèƒ½ (å« Debug è¦–çª—)
# ==========================================
tab1, tab2 = st.tabs(["ğŸ’¬ ç·šä¸Šä¿éšªè«®è©¢", "ğŸ“‹ æ™ºèƒ½ä¿éšªæ¨è–¦"])

with tab1:
    st.subheader("ğŸ’¡ æ™ºæ…§ä¿éšªé¡§å•")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ (ä¾‹å¦‚ï¼šæ—¥æœ¬æ—…éŠéšªæ¨è–¦)..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ” AI æ­£åœ¨ç¿»é–±æ¢æ¬¾ä¸¦é€²è¡Œæ¨ç†..."):
                try:
                    # Debug: é¡¯ç¤ºæŠ“åˆ°çš„è³‡æ–™
                    retrieved_docs = retriever.invoke(prompt)
                    
                    with st.expander("ğŸ•µï¸ [å·¥ç¨‹å¸«æ¨¡å¼] é»æ“ŠæŸ¥çœ‹ AI è®€åˆ°äº†å“ªäº›è³‡æ–™"):
                        if not retrieved_docs:
                            st.warning("âš ï¸ ç³»çµ±æ²’æœ‰æŠ“åˆ°ä»»ä½•è³‡æ–™ã€‚")
                        for i, doc in enumerate(retrieved_docs):
                            source = doc.metadata.get('source', doc.metadata.get('filename', 'æœªçŸ¥ä¾†æº'))
                            st.markdown(f"**ğŸ“„ åƒè€ƒæ–‡ä»¶ {i+1} ({source})**")
                            st.caption(doc.page_content[:300] + "...") 
                            st.divider()

                    # ç”¢ç”Ÿå›ç­”
                    response = qa_chain.invoke(prompt)
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

with tab2:
    st.subheader("ğŸ“‹ ç‚ºæ‚¨é‡èº«æ‰“é€ çš„ä¿éšªè¦åŠƒ")
    with st.container(border=True):
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("æ€§åˆ¥", ["ç”·", "å¥³"])
            age = st.number_input("å¹´é½¡", 25, 100, 30)
            job = st.text_input("è·æ¥­ (å½±éŸ¿é¢¨éšªç­‰ç´š)", "å·¥ç¨‹å¸«") # æç¤ºä½¿ç”¨è€…é€™å¾ˆé‡è¦
        with col2:
            salary = st.selectbox("å¹´æ”¶", ["50è¬ä»¥ä¸‹", "50-100è¬", "100-200è¬", "200è¬ä»¥ä¸Š"])
            budget = st.text_input("é ç®— (ä¾‹å¦‚ï¼šå¹´ç¹³2è¬)", "æœˆç¹³ 3000")
        
        ins_type = st.selectbox("éšªç¨®", ["é†«ç™‚éšª", "æ„å¤–éšª", "å„²è“„éšª", "æ—…éŠéšª", "é•·ç…§éšª", "å£½éšª"])
        
        extra_info = ""
        if ins_type == "æ—…éŠéšª":
            dest = st.text_input("åœ‹å®¶ (ä¾‹å¦‚ï¼šæ—¥æœ¬)", "æ—¥æœ¬")
            days = st.number_input("å¤©æ•¸", 1, 365, 5)
            extra_info = f"é è¨ˆå‰å¾€{dest}æ—…éŠ{days}å¤©"

        if st.button("é–‹å§‹ AI æ·±åº¦åˆ†æ"):
            with st.spinner("ğŸ§  AI æ­£åœ¨è¨ˆç®—è·æ¥­ç­‰ç´šã€åˆ†ææ¢æ¬¾ä¸¦é€²è¡Œè·¨å…¬å¸æ¯”å°..."):
                # ==========================================
                # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šå‡ç´šç‰ˆ Prompt (åŠ å…¥å•†æ¥­é‚è¼¯)
                # ==========================================
                query = f"""
                ã€ä½¿ç”¨è€…ç•«åƒã€‘ï¼š
                - æ€§åˆ¥ï¼š{gender}
                - å¹´é½¡ï¼š{age} æ­² (è«‹æ³¨æ„æ­¤å¹´é½¡å±¤çš„æŠ•ä¿é™åˆ¶èˆ‡ä¿è²»è¶¨å‹¢)
                - è·æ¥­ï¼š{job} (è«‹å…ˆåˆ¤æ–·æ­¤è·æ¥­çš„ä¿éšªé¢¨éšªç­‰ç´šï¼Œå¦‚å…§å‹¤ç‚ºç¬¬1é¡ï¼Œå¤–å‹¤æˆ–é«”åŠ›å‹å‹•å¯èƒ½ç‚ºç¬¬2-6é¡)
                - ç¶“æ¿Ÿç‹€æ³ï¼šå¹´æ”¶ {salary}ï¼Œé ç®— {budget}
                - ç›®æ¨™éšªç¨®ï¼š{ins_type}
                - è£œå……æ¢ä»¶ï¼š{extra_info}

                ã€ä»»å‹™è¦æ±‚ã€‘ï¼š
                1. **é¢¨éšªè©•ä¼°**ï¼šé¦–å…ˆåˆ†æä½¿ç”¨è€…çš„ã€Œè·æ¥­é¢¨éšªç­‰ç´šã€èˆ‡ã€Œå¹´é½¡éœ€æ±‚ã€ã€‚(ä¾‹å¦‚ï¼šæ„å¤–éšªéœ€ç‰¹åˆ¥é—œæ³¨è·æ¥­ç­‰ç´šï¼›é†«ç™‚éšªéœ€é—œæ³¨å¹´é½¡è²»ç‡)ã€‚
                2. **å¤šå…ƒæœå°‹**ï¼šè«‹å¾è³‡æ–™åº«ä¸­æª¢ç´¢æ¢æ¬¾ï¼Œ**å‹™å¿…å˜—è©¦å°‹æ‰¾ã€Œ2å®¶ä¸åŒä¿éšªå…¬å¸ã€**çš„é¡ä¼¼å•†å“(è‹¥è³‡æ–™åº«æœ‰)ã€‚
                3. **æ¨è–¦æ–¹æ¡ˆ**ï¼šæ¨è–¦ 2 å€‹å…·é«”çš„ä¿éšªå•†å“ã€‚
                4. **æ¯”è¼ƒåˆ†æ**ï¼šé‡å°é€™å…©å€‹å•†å“é€²è¡Œå„ªç¼ºé»æ¯”è¼ƒ (ä¾‹å¦‚ï¼šAå•†å“ä¿è²»ä½ä½†é¡åº¦å°‘ï¼ŒBå•†å“ä¿éšœç¯„åœå»£ä½†è¼ƒè²´)ã€‚

                ã€è¼¸å‡ºæ ¼å¼ç¯„ä¾‹ã€‘ï¼š
                ### ğŸ§‘â€ğŸ’¼ ä½¿ç”¨è€…éœ€æ±‚åˆ†æ
                (åœ¨æ­¤èªªæ˜è·æ¥­é¢¨éšªèˆ‡å¹´é½¡å»ºè­°...)

                ### ğŸ† æ¨è–¦å•†å“ 1ï¼š[å…¬å¸åç¨±] - [å•†å“åç¨±]
                * ç‰¹è‰²ï¼š...
                * é©åˆåŸå› ï¼š...

                ### ğŸ¥ˆ æ¨è–¦å•†å“ 2ï¼š[å…¬å¸åç¨±] - [å•†å“åç¨±]
                * ç‰¹è‰²ï¼š...
                * é©åˆåŸå› ï¼š...

                ### âš–ï¸ ç¶œåˆæ¯”è¼ƒ
                (è¡¨æ ¼æˆ–æ–‡å­—æ¯”è¼ƒ...)
                """
                
                # 1. åŸ·è¡Œæª¢ç´¢ (ä¿ç•™ Debug æ¨¡å¼ï¼Œè®“æ‚¨ç¢ºèªå®ƒæœ‰æ²’æœ‰æŠ“åˆ°ä¸åŒå…¬å¸çš„è³‡æ–™)
                retrieved_docs = retriever.invoke(query)
                with st.expander("ğŸ•µï¸ [å·¥ç¨‹å¸«æ¨¡å¼] AI æª¢ç´¢åˆ°çš„æ¢æ¬¾å…§å®¹"):
                    for i, doc in enumerate(retrieved_docs):
                        # é¡¯ç¤ºä¾†æºï¼Œç¢ºèªæ˜¯å¦æœ‰æŠ“åˆ°ä¸åŒå…¬å¸
                        source = doc.metadata.get('source', doc.metadata.get('filename', 'æœªçŸ¥'))
                        company = doc.metadata.get('company', 'æœªçŸ¥å…¬å¸') # å‡è¨­æˆ‘å€‘ metadata æœ‰å­˜å…¬å¸
                        st.markdown(f"**ğŸ“„ ä¾†æº {i+1} ({company}): {source}**")
                        st.caption(doc.page_content[:300] + "...")
                        st.divider()

                # 2. ç”Ÿæˆå›ç­”
                response = qa_chain.invoke(query)
                st.markdown(response)