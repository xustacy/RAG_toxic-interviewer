import streamlit as st
import os
import gdown
import zipfile
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

# ==========================================
# 1. ç³»çµ±è¨­å®š
# ==========================================
st.set_page_config(page_title="å°ˆæ¥­ä¿éšªè«®è©¢ AI", layout="wide")
st.title("ğŸ›¡ï¸ å°ˆæ¥­ä¿éšªè«®è©¢èˆ‡æ¨è–¦ç³»çµ±")

# æª¢æŸ¥ Groq é‡‘é‘°
if "GROQ_API_KEY" in st.secrets:
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    api_key = st.secrets["GROQ_API_KEY"]
else:
    st.error("âŒ æœªè¨­å®š GROQ_API_KEYï¼Œè«‹è‡³ Streamlit Secrets è¨­å®šã€‚")
    st.stop()

# ==========================================
# 2. è¨­å®š Google Drive ä¸‹è¼‰
# ==========================================
# é€™æ˜¯æ‚¨å‰›å‰›æä¾›çš„æª”æ¡ˆ ID
GDRIVE_FILE_ID = "1SWLCi36AvdoOO8oTAflVD9luHyDKQbRL" 
ZIP_NAME = "faiss_db_mini.zip"
DB_FOLDER = "faiss_db_mini"

# ==========================================
# 3. å®šç¾© Embedding æ¨¡å‹ (é—œéµä¿®æ”¹ï¼)
# ==========================================
def get_embeddings():
    """ä½¿ç”¨èˆ‡è³‡æ–™åº«ä¸€è‡´çš„ MiniLM æ¨¡å‹ (ç¶­åº¦ 384)"""
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )

# ==========================================
# 4. è¼‰å…¥è³‡æº (ä¸‹è¼‰ -> è§£å£“ -> è®€å–)
# ==========================================
@st.cache_resource
def load_resources():
    # ä¸‹è¼‰èˆ‡è§£å£“ç¸®
    if not os.path.exists(DB_FOLDER):
        if not os.path.exists(ZIP_NAME):
            with st.spinner("ğŸ“¦ æ­£åœ¨å¾é›²ç«¯ä¸‹è¼‰è³‡æ–™åº«..."):
                try:
                    url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}'
                    gdown.download(url, ZIP_NAME, quiet=False)
                except Exception as e:
                    st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")
                    return None
        
        with st.spinner("ğŸ“‚ è§£å£“ç¸®è³‡æ–™åº«..."):
            try:
                with zipfile.ZipFile(ZIP_NAME, 'r') as zip_ref:
                    zip_ref.extractall(".")
            except Exception as e:
                st.error(f"è§£å£“ç¸®å¤±æ•—: {e}")
                return None

    # è¼‰å…¥ FAISS
    try:
        embeddings = get_embeddings()
        
        # å˜—è©¦è¼‰å…¥è³‡æ–™åº«
        # å„ªå…ˆæª¢æŸ¥ faiss_db_mini è³‡æ–™å¤¾ï¼Œè‹¥ç„¡å‰‡æª¢æŸ¥ç•¶å‰ç›®éŒ„
        if os.path.exists(DB_FOLDER):
            load_path = DB_FOLDER
        else:
            load_path = "."
            
        db = FAISS.load_local(
            load_path, 
            embeddings,
            allow_dangerous_deserialization=True
        )
        st.success("âœ… è³‡æ–™åº«è¼‰å…¥æˆåŠŸï¼")
        return db
    except Exception as e:
        st.error(f"è³‡æ–™åº«è®€å–å¤±æ•—ï¼š{e}")
        st.info("æç¤ºï¼šè«‹ç¢ºèª requirements.txt æ˜¯å¦åŒ…å« faiss-cpu èˆ‡ sentence-transformers")
        return None

vectorstore = load_resources()

if not vectorstore:
    st.stop()

retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# è¨­å®š LLM (ä½¿ç”¨ Groq)
llm = ChatOpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=api_key,
    model="llama3-70b-8192", 
    temperature=0.3,         
)

# ==========================================
# 5. Prompt èˆ‡ Chain è¨­å®š
# ==========================================
persona_instruction = """
ä½ æ˜¯å°ˆæ¥­ä¸”å……æ»¿ç†±å¿±çš„ä¿éšªæ¥­å‹™å“¡ï¼Œè‡´åŠ›æ–¼æä¾›æœ€å„ªè³ªçš„æœå‹™ã€‚
è«‹å‹™å¿…åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
1. **åªèƒ½**æ ¹æ“šä¸‹æ–¹çš„ã€å·²çŸ¥è³‡è¨Šã€‘ä¾†å›ç­”å•é¡Œã€‚
2. è‹¥è³‡æ–™ä¸è¶³æˆ–é¡Œç›®è¶…éèƒ½åŠ›ç¯„åœï¼Œè«‹å›ç­”ï¼šã€Œä¸å¥½æ„æ€ï¼Œç›®å‰çš„å…§éƒ¨è³‡æ–™åº«ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œå»ºè­°æ‚¨ç›´æ¥æ´½è©¢è©²ä¿éšªå…¬å¸çš„å°ˆäººå®¢æœæœå‹™ã€‚ã€
3. **æ‹’çµ•å›ç­”**ä»»ä½•è·Ÿä¿éšªä»¥å¤–ç›¸é—œå…§å®¹ã€‚
4. èªæ°£ä¿æŒè¦ªåˆ‡å‹å–„ã€å°ˆæ¥­ç°¡æ½”ï¼Œä¸¦ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ã€‚
"""

qa_prompt = ChatPromptTemplate.from_messages([
    ("system", persona_instruction + "\n\nã€å·²çŸ¥è³‡è¨Šã€‘ï¼š\n{context}"),
    ("human", "{question}")
])

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

qa_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | qa_prompt
    | llm
    | StrOutputParser()
)

# ==========================================
# 6. ä»‹é¢åŠŸèƒ½
# ==========================================
tab1, tab2 = st.tabs(["ğŸ’¬ ç·šä¸Šä¿éšªè«®è©¢", "ğŸ“‹ æ™ºèƒ½ä¿éšªæ¨è–¦"])

with tab1:
    st.subheader("æœ‰ä»€éº¼ä¿éšªå•é¡Œæˆ‘å¯ä»¥å¹«æ‚¨å—ï¼Ÿ")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æŸ¥é–±ä¿éšªæ¢æ¬¾..."):
                try:
                    response = qa_chain.invoke(prompt)
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"éŒ¯èª¤ï¼š{e}")

with tab2:
    st.subheader("ç‚ºæ‚¨é‡èº«æ‰“é€ çš„ä¿éšªè¦åŠƒ")
    with st.container(border=True):
        col1, col2 = st.columns(2)
        with col1:
            gender = st.selectbox("æ€§åˆ¥", ["ç”·", "å¥³"])
            age = st.number_input("å¹´é½¡", 25, 100, 30)
            job = st.text_input("è·æ¥­", "å·¥ç¨‹å¸«")
        with col2:
            salary = st.selectbox("å¹´æ”¶", ["50è¬ä»¥ä¸‹", "50-100è¬", "100-200è¬", "200è¬ä»¥ä¸Š"])
            budget = st.text_input("é ç®—", "æœˆç¹³ 3000")
        
        ins_type = st.selectbox("éšªç¨®", ["é†«ç™‚éšª", "æ„å¤–éšª", "å„²è“„éšª", "æ—…éŠéšª", "é•·ç…§éšª", "å£½éšª"])
        
        extra_info = ""
        if ins_type == "æ—…éŠéšª":
            dest = st.text_input("åœ‹å®¶")
            days = st.number_input("å¤©æ•¸", 1, 365, 5)
            extra_info = f"å»{dest}æ—…éŠ{days}å¤©"

        if st.button("é–‹å§‹åˆ†æ"):
            with st.spinner("åˆ†æä¸­..."):
                query = f"ä½¿ç”¨è€…ï¼š{gender}, {age}æ­², è·æ¥­{job}, å¹´æ”¶{salary}, é ç®—{budget}ã€‚æƒ³æ‰¾{ins_type}ã€‚{extra_info}ã€‚è«‹æ¨è–¦å•†å“ã€‚"
                response = qa_chain.invoke(query)
                st.markdown(response)